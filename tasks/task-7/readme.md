# Task-7. Machine Learning. Linear Algebra in the Context of Linear Methods
Link: [Task-7.MATH-ML-2. Practice. Notebook.ipynb](https://github.com/helios12/DataScienceProjects/blob/main/tasks/task-7/Task-7.MATH-ML-2. Practice. Notebook.ipynb)

The goal of the task was to experiment with linear regression, starting at the low level with Ordinary Least Squares method, proceeding with the standard sklearn linear regression, adding polynomial features, $L_1$ and $L_2$ -regularizations and hyperparameter optimization for the regularization.

## Technology Stack
While working on this task I have mastered:

* python
* sklearn
* linear algebra

## Conclusions
In the course of the work I have shown that the MAPE metric value on the validation data-folds is gradually improving by adding polynomial features and regularization. In the current case $L_1$-regularization has delivered a better result. Hyperparameter optimization has proven itself to be a valuable tool to optimize the regularization parameters.