{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "В данном проекте вы решите настоящую бизнес-задачу в области маркетинга. Вам предстоит произвести сегментацию клиентов на основе их покупательской способности, частоты совершения заказов и срока давности последнего заказа, а также определить оптимальную стратегию взаимодействия с ними.\n",
    "<center> <img src=https://salesupnow.ru/storage/app/media/pipeople.png align=\"right\" width=\"300\"/> </center>\n",
    "\n",
    "Маркетинг — неотъемлемая часть любого бизнеса. Для повышения прибыли компании важно понимать своего клиента, его пожелания и предпочтения. С появлением электронной коммерции, или онлайн-продаж, стало намного проще собирать данные о клиентах, анализировать их, находить закономерности и реализовывать маркетинговые кампании.\n",
    "\n",
    "Большинство интернет-магазинов используют инструменты веб-аналитики, чтобы отслеживать просмотры страниц, количество и поведение посетителей и коэффициент отказов. Но отчёта из Google Analytics или аналогичной системы может быть недостаточно для полного понимания того, как клиенты взаимодействуют с сайтом. Компаниям важно иметь возможность быстро и точно реагировать на перемены в поведении клиентов, создавая инструменты, которые обнаруживают эти изменения практически в режиме реального времени.\n",
    "\n",
    "Машинное обучение помогает поисковой системе анализировать огромное количество данных о посетителях платформы, узнавать модели поведения профессиональных покупателей, определять категорию клиентов (например, лояльные/перспективные/новички/спящие/ушедшие) и выбирать правильную стратегию взаимодействия с ними.\n",
    "\n",
    "Стоит также отметить, что компании, использующие машинное обучение на своих платформах электронной коммерции, могут постоянно повышать эффективность бизнес-процессов: настраивать товарную выборку персонально для каждого покупателя и предлагать выгодную цену в соответствии с бюджетом клиента и т. д. Эта задача относится к категории построения рекомендательных систем, речь о которых пойдёт в следующем разделе нашего курса.\n",
    "\n",
    "Как правило, наборы данных для электронной коммерции являются частной собственностью и, следовательно, их трудно найти среди общедоступных данных. \n",
    "\n",
    "**Бизнес-задача:** произвести сегментацию существующих клиентов, проинтерпретировать эти сегменты и определить стратегию взаимодействия с ними.\n",
    "\n",
    "**Техническая задача для вас как для специалиста в Data Science:** построить модель кластеризации клиентов на основе их покупательской способности, частоты заказов и срока давности последней покупки, определить профиль каждого из кластеров.\n",
    "\n",
    "**Основные цели проекта:**\n",
    "1. Произвести предобработку набора данных.\n",
    "2. Провести разведывательный анализ данных и выявить основные закономерности.\n",
    "3. Сформировать категории товаров и клиентов. \n",
    "4. Построить несколько моделей машинного обучения, решающих задачу кластеризации клиентов, определить количество кластеров и проинтерпретировать их.\n",
    "5. Спроектировать процесс предсказания категории интересов клиента и протестировать вашу модель на новых клиентах.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Знакомство с данными. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn import mixture\n",
    "from sklearn import manifold\n",
    "from sklearn import pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import decomposition\n",
    "from sklearn import ensemble\n",
    "import warnings \n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первым делом необходимо понять, с какими данными нам предстоит работать, и произвести базовую предобработку данных, переведя признаки в необходимые для дальнейшей работы форматы.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала давайте познакомимся с нашими данными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"./data/data.csv\", \n",
    "    encoding=\"ISO-8859-1\", \n",
    "    dtype={'CustomerID': str,'InvoiceID': str}\n",
    ")\n",
    "print('Data shape: {}'.format(data.shape))\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, у нас есть данные о более чем полумиллионе транзакций. Каждая из них описывается следующими признаками:\n",
    "\n",
    "* InvoiceNo — номер счёта-фактуры (уникальный номинальный шестизначный номер, присваиваемый каждой транзакции; буква \"C\" в начале кода указывает на отмену транзакции);\n",
    "* Stock Code — код товара (уникальное пятизначное целое число, присваиваемое каждому отдельному товару);\n",
    "* Description — название товара;\n",
    "* Quantity — количество каждого товара за транзакцию; \n",
    "* InvoiceDate — дата и время выставления счёта/проведения транзакции;\n",
    "* UnitPrice — цена за единицу товара в фунтах стерлингов;\n",
    "* CustomerID — идентификатор клиента (уникальный пятизначный номер, однозначно присваиваемый каждому клиенту);\n",
    "* Country — название страны, в которой проживает клиент.\n",
    "\n",
    "Проведём анализ структуры таблицы.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.1\n",
    "Сколько столбцов в данных кодируются числовыми типами (int/float)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e8ffbb4aa2df86ecb4e84cec0b56acd7c47fe51a",
    "tags": []
   },
   "source": [
    "### Задание 2.2\n",
    "Выберите столбцы, в которых есть хотя бы один пропуск:\n",
    "* InvoiceNo\n",
    "* StockCode\n",
    "* Description\n",
    "* CustomerID\n",
    "* Country "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.3\n",
    "Судя по описанию задачи, нам должны были предоставить данные за годовой период — проверим, так ли это.\n",
    "\n",
    "Преобразуйте столбец InvoiceDate в формат datetime.\n",
    "Укажите, за какой промежуток времени представлены данные:\n",
    "\n",
    "* 2010-12-01 to 2011-12-09\n",
    "* 2011-12-01 to 2012-12-09\n",
    "* 2010-01-01 to 2011-01-09\n",
    "* 2020-12-01 to 2021-12-09\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.4\n",
    "\n",
    "1) Каково максимальное количество товаров в заказе (Quantity)? Ответ приведите в виде целого числа.\n",
    "\n",
    "2) Каково минимальное количество товаров в заказе (Quantity)? Ответ приведите в виде целого числа.\n",
    "\n",
    "3) Сколько, согласно данным, стоит самый дешёвый товар (за исключением товаров с отрицательной стоимостью)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.5\n",
    "1) Сколько уникальных клиентов покупали товары за период выгрузки датасета?\n",
    "\n",
    "2) Сколько уникальных стран содержится в столбце Country (исключая специальный код 'Unspecified', обозначающий неопределенную страну)?\n",
    "\n",
    "3) Укажите идентификатор самого популярного товара (StockCode):\n",
    "* 85123A\n",
    "* 64812\n",
    "* 51242\n",
    "* 24151B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Предобработка и очистка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом этапе нам предстоит подготовить наш датасет для дальнейшего моделирования, произведя очистку данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Задание 3.1\n",
    "Начнем с пропусков. \n",
    "\n",
    "1) Сколько всего в таблице пропущенных значений?\n",
    "\n",
    "2) Пропуски в столбце с идентификатором клиента и описанием товара свидетельствуют о некорректных/незавершённых транзакциях.\n",
    "\n",
    "Удалите строки, содержащие пропуски в этих столбцах. Сколько строк осталось в таблице?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.2\n",
    "Следом за пропусками проверим наличие дубликатов.\n",
    "\n",
    "1) Сколько в таблице полностью дублирующихся записей?\n",
    "\n",
    "2) Удалите дубликаты из таблицы. Сколько строк осталось?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее мы заметили, что в столбце с количеством товара есть отрицательные значения. Давайте разберемся, откуда они взялись. Выведем первые 5 строк таблицы, в которой столбец Quantity меньше 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_quantity = data[(data['Quantity']<0)]\n",
    "print('Count of entries with a negative number: {}'.format(negative_quantity.shape[0]))\n",
    "negative_quantity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.3\n",
    "Давайте проверим, что все записи из таблицы с отрицательным количеством товара действительно являются возвратными транзакциями. Если транзакция не является возвратом, но содержит отрицательное количество товара, это будет поводом считать её выбросом.\n",
    "\n",
    "Сколько транзакций из таблицы negative_quantity не содержат в номере заказа признак возврата?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте подробнее разберёмся с возвратами. Сейчас на каждый уникальный товар заведена отдельная строка в таблице — это мешает определить общее количество возвратов.\n",
    "\n",
    "Чтобы подсчитать число возвратов, сначала необходимо определить, сколько уникальных товаров указано в транзакции (корзине/basket) для каждой уникальной пары «клиент-заказ»:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['InvoiceDate'].count()\n",
    "nb_products_per_basket = temp.rename(columns = {'InvoiceDate':'Number of products'})\n",
    "nb_products_per_basket.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.4\n",
    "Добавьте во вспомогательную таблицу nb_products_per_basket признак отмены заказа (order_canceled): он равен 1, если транзакция является возвратом, и 0 — в противном случае.\n",
    "\n",
    "Сколько процентов заказов в таблице являются возвратами? Ответ приведите в виде целого числа.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте поближе взглянем на отмененные заказы:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_products_per_basket[nb_products_per_basket['order_canceled']==1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем в таблице со всеми транзакциями записи принадлежащие клиенту с идентификатором 12346:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[data['CustomerID'] == '12346']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, вот пример пары «заказ-отмена». Обратите внимание на столбцы StockCode, UnitPrice, CustomerID и Quantity, сравните их для двух транзакций. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.5\n",
    "Выдвигаем гипотезу: для каждой отменённой транзакции в базе данных (таблица data) существует её аналог с тем же кодом товара, идентификатором клиента и противоположным значением количества товара.\n",
    "\n",
    "* Верна ли гипотеза?\n",
    "* Да, верна\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте приведем контр-пример, на котором \"споткнулась\" наша прошлая гипотеза. Посмотрим на клиента с идентификатором 14527:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[data['CustomerID'] == '14527'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на первую строку, в которой располагается заказ C536379 с признаком отмены — противоположных ему аналогов по количеству товаров вы не найдёте. Причина кроется в типе товара: данный товар обозначен как товар со скидкой (StockCode), и, по-видимому, для таких транзакций нет аналогов с положительным числом товаров в заказе. Учтём это наблюдение на будущее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.6\n",
    "Выдвигаем новую гипотезу: для каждой отменённой транзакции в базе данных (таблица data) существует её аналог с тем же кодом товара, идентификатором клиента и противоположным значением количества товара, если на товар не распространяются скидки.\n",
    "\n",
    "Верна ли гипотеза?\n",
    "* Да, верна\n",
    "* Нет, не верна \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, где кроется наша проблема. В качестве контр-примера приведем транзакции, относящиеся к клиенту с идентификатором 15311 и товаром под кодом 35004C:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[(data['CustomerID'] == '15311') & (data['StockCode'] == '35004C')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* На первой строке мы видим заказ с отменой (номер заказа начинается с символа C). Однако возникает вопрос: на какой заказ пришла эта отмена, ведь более ранних записей о транзакциях, связанных с этим клиентом, нет.\n",
    "Ответ состоит в том, что заказ на покупку данного товара от клиента поступил раньше декабря 2010 года, а этих данных в нашей таблице нет. Это очень популярная проблема, которая возникает практически при любой работе с транзакциями: есть только фрагмент из общих данных, однако неизвестно, что предшествовало этому фрагменту.\n",
    "\n",
    "* По двум следующим строкам видно, что клиент может отменить не весь заказ, а только его часть (5 декабря клиент покупает 12 единиц товара, а 8 декабря оформляет возврат только на одну единицу товара). Мы должны принять это во внимание на будущее\n",
    "\n",
    "Итак, теперь мы знаем все особенности отмены заказов. При сегментировании клиентов мы будем определять их покупательскую способность, а для этого очень важно учитывать возвраты товаров. Поэтому давайте создадим в данных о транзакциях признак QuantityCanceled, который будет указывать на количество возвращённого впоследствии товара для каждой транзакции. \n",
    "\n",
    "Сразу обговорим, что мы не будем учитывать сложные пограничные случаи:\n",
    "1. Отменённая транзакция не имеет противоположной (на транзакцию-возврат не нашлось ни одной транзакции на покупку).\n",
    "2. Количество возвращённого товара в транзакции-возврате больше, чем количество товара, которое указано в любой из отдельных транзакций на покупку (это случай, когда клиент сделал несколько заказов одного и того же товара, а потом оформил возврат на все товары разом).\n",
    "\n",
    "\n",
    "Мы подготовили для вас функцию get_quantity_canceled(). Она принимает на вход таблицу с транзакциями и возвращает объект Series — столбец, в котором указано количество возвращённого впоследствии товара для каждой транзакции. На основе результата работы этой функции мы создаём в таблице с транзакциями новый столбец QuantityCanceled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantity_canceled(data):\n",
    "    # Инициализируем Series той же длины, что и столбцы таблицы, нулями\n",
    "    quantity_canceled = pd.Series(np.zeros(data.shape[0]), index=data.index)    \n",
    "    negative_quantity = data[(data['Quantity'] < 0)].copy()\n",
    "    for col in negative_quantity.itertuples():\n",
    "        # Создаем DataFrame из всех контрагентов\n",
    "        df_test = data[(data['CustomerID'] == col.CustomerID) &\n",
    "                       (data['StockCode']  == col.StockCode) & \n",
    "                       (data['InvoiceDate'] < col.InvoiceDate) & \n",
    "                       ((quantity_canceled.loc[col.Index] - col.Quantity) <= data['Quantity'])].copy()\n",
    "        # Транзация-возврат не имеет контрагента - ничего не делаем\n",
    "        if (df_test.shape[0] == 0): \n",
    "            continue\n",
    "        # Транзакция-возврат имеет одного и более контрагентов\n",
    "        # Добавляем количество отмененного в столбец QuantityCanceled \n",
    "        else:\n",
    "            df_test.sort_index(axis=0 ,ascending=False, inplace = True)\n",
    "            index_order = df_test.index[0]\n",
    "            quantity_canceled.loc[index_order] = quantity_canceled.loc[index_order] - col.Quantity       \n",
    "    return quantity_canceled\n",
    "\n",
    "quantity_canceled = get_quantity_canceled(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.7\n",
    "Подсчитайте суммарное количество отмененных товаров в столбце QuantityCanceled. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3.8\n",
    "Теперь, когда мы разобрались с транзакциями-возвратами, они больше нам не понадобятся. \n",
    "Удалите из таблицы транзакции, в поле которых указано отрицательное количество товара.  \n",
    "Сколько записей осталось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующая проблема — это специальные виды транзакций. Например, ранее мы уже видели, что для товаров со скидкой признак StockCode обозначен как 'D'. Давайте проверим, бывают ли другие специальные коды.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.9\n",
    "С помощью регулярных выражений найдите такие коды товаров (StockCode), которые начинаются с латинских букв (при этом коды могут содержать цифры). \n",
    "\n",
    "Подсказка: Поиск подстрок в столбце можно организовать с помощью str.contains(). В качестве шаблона для поиска используйте строку '^[a-zA-Z]+'. Параметр regex установите в значение True.\n",
    "\n",
    "1) Сколько уникальных специальных видов транзакций вам удалось найти?\n",
    "\n",
    "Специальные операции не характеризуют наших клиентов, поэтому такие записи нам не нужны. Удалите все специальные транзакции из таблицы. \n",
    "\n",
    "2) Сколько записей осталось?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.10\n",
    "Ранее при просмотре описательных статистик мы видели, что на некоторые товары установлена цена в 0 фунтов стерлингов. \n",
    "\n",
    "1) В скольких транзакциях цена за единицу товара равна 0?\n",
    "\n",
    "2) Таких транзакций оказалось менее 1 %, поэтому от них можно просто избавиться. Удалите такие транзакции из таблицы. Сколько записей осталось?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поздравляем, этап очистки данных завершён. Рекомендуем сохранить полученный результат в отдельный файл, чтобы впоследствии вам не приходилось повторять эти действия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0869dfd28b3c5a7c0c39c026d73c1828ae7efbeb"
   },
   "source": [
    "## 4. Разведывательный анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте займёмся разведывательным анализом и исследуем транзакции.\n",
    "\n",
    "Перед нами стоят следующие задачи:\n",
    "* понять, клиенты из каких стран покупают больше и чаще;\n",
    "* узнать, присутствует ли в продажах сезонность (когда покупают чаще);\n",
    "* создать новые признаки, которые в дальнейшем понадобятся при формировании датасета о клиентах.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.1\n",
    "Для начала выясним, в каких странах живут клиенты.\n",
    "\n",
    "Постройте график, отражающий количество клиентов в каждой из стран. Обратите внимание, что нам нужны именно уникальные клиенты.\n",
    "\n",
    "В какой стране живёт наибольшее количество клиентов?\n",
    "\n",
    "* Великобритания (United Kingdom)\n",
    "* Германия (Germany)\n",
    "* Франция (France)\n",
    "* Нидерланды (Netherlands)\n",
    "* Ирландия (EIRE)\n",
    "* Австралия (Australia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.2\n",
    "Мы посмотрели на распределение клиентов в разрезе стран. А что насчёт заказов?\n",
    "\n",
    "Постройте визуализацию и выделите топ-3 стран по количеству поступающих заказов.\n",
    "\n",
    "* Великобритания (United Kingdom)\n",
    "* Германия (Germany)\n",
    "* Франция (France)\n",
    "* Нидерланды (Netherlands)\n",
    "* Ирландия (EIRE)\n",
    "* Австралия (Australia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.3\n",
    "Давайте добавим в датасет общую цену заказа, назовём её TotalPrice.\n",
    "Общая цена заказа рассчитывается как:\n",
    " \n",
    " **общая цена = цена за единицу товара * (количество товаров в заказе - количество возвращённых товаров).**\n",
    "\n",
    "Чему равна средняя общая стоимость заказов? Ответ приведите в фунтах стерлингов и округлите до целого числа.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.4\n",
    "\n",
    "Постройте визуализацию и выделите топ-3 стран, клиенты из которых приносят компании больше всего выручки:\n",
    "* Великобритания (United Kingdom)\n",
    "* Германия (Germany)\n",
    "* Франция (France)\n",
    "* Нидерланды (Netherlands)\n",
    "* Ирландия (EIRE)\n",
    "* Австралия (Australia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь займёмся временными характеристиками.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Задание 4.5\n",
    "Добавьте в таблицу с транзакциями признаки месяца, дня недели и часа совершения покупки.\n",
    "\n",
    "Постройте визуализацию, отражающую распределение суммарной выручки от заказов по месяцам. Укажите номер самого прибыльного для компании месяца. Предположите, почему так происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.6\n",
    "Постройте визуализацию количества заказов для каждого дня недели. Укажите день недели, в который, согласно данным, не совершено ни одного заказа:\n",
    "* Понедельник\n",
    "* Вторник\n",
    "* Среда\n",
    "* Четверг\n",
    "* Пятница\n",
    "* Суббота \n",
    "* Воскресенье\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.7\n",
    "Выделите дату из признака времени совершения транзакции.\n",
    "Сгруппируйте данные по датам и часам совершения транзакции и найдите количество заказов на каждый день-час. Затем найдите среднее количество ежедневно поступающих заказов в каждый из часов.\n",
    "\n",
    "Постройте визуализацию, отражающую распределение среднего количества ежедневно поступающих заказов по времени суток (часу совершения транзакции).\n",
    "\n",
    "Выберите верные утверждения:\n",
    "* Больше всего заказов совершается в дневное время в интервале от 18 до 20 часов\n",
    "* Больше всего заказов совершается в вечернее время в интервале от 10 до 15 часов\n",
    "* Начиная с 21 часа вечера и до 6 утра (не включительно) заказы не поступают \n",
    "* Заказы поступают во все периоды дня\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe334ef9f8165328fc14400be829499b0b2c46f1"
   },
   "source": [
    "## 5. RFM-сегментация клиентов: часть 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы добрались до самой интересной части нашей задачи. Нам предстоит сформировать признаки, на основе которых мы будем производить сегментацию клиентов.\n",
    "\n",
    "Для этого давайте познакомимся с очень популярным методом для анализа потребительской ценности под названием RFM. \n",
    "\n",
    "<center> <img src=https://miro.medium.com/max/1400/1*uYQjy9SUjW7iWHc2gGanQQ.png align=\"right\" width=\"400\"/> </center>\n",
    "\n",
    "Метод заключается в группировке клиентов на основе следующих параметров:\n",
    "* Recency (Давность) — давность последней покупки клиента;\n",
    "* Frequency (Частота) — общее количество покупок клиента;\n",
    "* Monetary Value (Денежная ценность) — сколько денег потратил клиент.\n",
    "\n",
    "\n",
    "Суть RFM-анализа состоит в том, что мы разделяем всех клиентов на группы в зависимости от того, как давно они сделали последнюю покупку, как часто покупали и насколько большой была сумма их заказов.\n",
    "\n",
    "Например, вот так может выглядеть интерпретация кластеров для случая RF-сегментации (анализа на основе давности и частоты заказов клиента):\n",
    "\n",
    "<img src=https://retailrocket.ru/wp-content/uploads/2017/06/rfm-1.png>\n",
    "\n",
    "Задача маркетологов — вести клиента в зону лояльных.\n",
    "\n",
    "Мы можем рассчитать RFM-характеристики для каждого из клиентов в нашем датасете и на их основе с помощью методов кластеризации построить подобные сегменты клиентов, привязанные к нашим данным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Задание 5.1\n",
    "\n",
    "Итак, приступим к созданию нашей RFM-таблицы. \n",
    "\n",
    "Чтобы получить RFM-таблицу, нам необходимо сгруппировать данные по идентификаторам клиента и рассчитать следующие  агрегированные характеристики:\n",
    "\n",
    "* Recency для i-го клиента рассчитывается как разница между датой и временем последнего заказа и точкой отсчёта, переведённая в дни:\n",
    "    $$t_0-max(t_{i1}, t_{i2},..., t_{iM})$$\n",
    "\n",
    "    где $t_{ij}$ — дата и время совершения i-ым клиентом своей j-ой покупки.\n",
    "\n",
    "    В качестве точки отсчёта $t_0$ берём дату на один день «старше», чем все наши данные. Это будет 10 декабря 2011 года (в формате datetime — '2011-12-10 00:00:00').\n",
    "\n",
    "* Frequency рассчитывается как общее количество уникальных заказов, которые совершил i-ый клиент.\n",
    "* Monetary Value рассчитывается как общая сумма денег, которую i-ый клиент потратил на наши товары (с учетом возвратов).\n",
    "\n",
    "Когда вы рассчитаете все характеристики, не забудьте дать столбцам результирующей таблицы соответствующие названия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Сколько клиентов совершили покупку более 200 дней назад?\n",
    "\n",
    "2) Сколько заказов в среднем делает клиент (за представленный годовой период)? Ответ округлите до целого числа.\n",
    "\n",
    "3) Чему равна общая сумма денег, которую потратил клиент с идентификатором 12360? Ответ приведите в фунтах стерлингов и округлите до целого числа.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте взглянем на коробчатые диаграммы для каждого из признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = [px.box(rfm_table, x=column) for column in rfm_table.columns]\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=3, \n",
    "    subplot_titles=(\n",
    "        \"Recency\",\"Frequency\", \"Monetary\"\n",
    "    )\n",
    ")\n",
    "\n",
    "for i, box in enumerate(boxes):\n",
    "    fig.add_trace(boxes[i]['data'][0], row=1, col=i+1)\n",
    "\n",
    "fig.update_layout(showlegend=True)\n",
    "fig.write_html('plotly/boxplot_1.html')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что интересного здесь можно увидеть? Есть клиенты с аномально большим количеством сделанных заказов (более 100 штук), а также клиенты, общая стоимость заказов которых превышает 190 тысяч фунтов стерлингов.\n",
    "\n",
    "Чем это плохо? Выбросы могут отрицательно сказаться на результатах работы методов кластеризации, неустойчивых к ним, например алгоритма KMeans, поэтому хотелось бы от них избавиться. Однако терять много ценных данных о клиентах тоже не хочется, поэтому ограничимся верхней границей соответствующей квантили уровня 0.95. Таким образом, мы удалим данные тех клиентов, для которых значение параметра Frequency или параметра Monetary выше, чем у 95 % клиентов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5.2\n",
    "Удалите из RFM-таблицы записи о клиентах, для которых выполняется хотя бы одно из условий:\n",
    "\n",
    "$$frequency >frequency_{0.95}$$\n",
    "$$monetary >monetary_{0.95}$$ \n",
    "\n",
    "где $frequency_{0.95}$ и $monetary_{0.95}$ - квантили уровня 0.95 для соответствующих признаков. \n",
    "\n",
    "Данные о скольких клиентах у вас остались в RFM-таблице?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После удаления выбросов у вас должны получиться следующие коробчатые диаграммы:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = [px.box(rfm_table_cleaned, x=column) for column in rfm_table_cleaned.columns]\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=3, \n",
    "    subplot_titles=(\n",
    "        \"Recency\", \"Frequency\", \"Monetary\"\n",
    "    )\n",
    ")\n",
    "\n",
    "for i, box in enumerate(boxes):\n",
    "    fig.add_trace(boxes[i]['data'][0], row=1, col=i+1)\n",
    "\n",
    "fig.update_layout(showlegend=True)\n",
    "fig.write_html('plotly/boxplot_2.html')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы наконец добрались до этапа кластеризации. Для начала нам необходимо оценить, как распределены наблюдения в пространстве признаков. Благо, у нас всего три параметра, по которым мы хотим кластеризовать клиентов, поэтому данные можно визуализировать в виде трёхмерной диаграммы рассеяния. \n",
    "\n",
    "Построим визуализацию нашего трёхмерного пространства признаков:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим трёхмерный объект\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = Axes3D(fig)\n",
    "# добавим дополнительную ось в объект картинки\n",
    "fig.add_axes(ax)\n",
    "ax.azim = 20\n",
    "ax.elev = 30\n",
    "\n",
    "# визуализируем данные, передав значения x, y, z, а также информацию о группировке данных по цветам\n",
    "ax.scatter(\n",
    "    rfm_table_cleaned['Recency'].to_list(), \n",
    "    rfm_table_cleaned['Frequency'].to_list(),\n",
    "    rfm_table_cleaned['Monetary'].to_list()\n",
    ")\n",
    "# добавим оси\n",
    "ax.set_xlabel('Recency')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Monetary');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что здесь можно увидеть? На самом деле, ничего конкретного. Да, видно, что есть клиенты с большими значениями параметров Monetary и Frequency — вероятно, это лучшие клиенты, которые покупают чаще всего и приносят больше всего денег. Однако по общей массе точек сложно сказать, сколько кластеров у нас есть — скорее даже кажется, что пространство не поддаётся кластеризации.\n",
    "\n",
    "Давайте призовём на помощь методы снижения размерности.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5.3\n",
    "Начнём с метода главных компонент (PCA). Нам известно, что для его стабильной работы данные необходимо стандартизировать/нормализовать. \n",
    "\n",
    "Давайте для удобства обернём эти шаги по предобработке данных в pipeline.\n",
    "\n",
    "Создайте pipeline, в котором будут следующие шаги:\n",
    "* стандартизация с помощью StandardScaler с параметрами по умолчанию; \n",
    "* метод главных компонент с двумя компонентами.\n",
    "\n",
    "Обучите ваш pipeline на RFM-таблице, очищенной от выбросов, и примените к ней трансформацию.\n",
    "\n",
    "Какую долю дисперсии исходных данных объясняет первая главная компонента? Ответ округлите до двух знаков после точки-разделителя.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализировав пространство главных компонент после декомпозиции мы получим следующую картину:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=rfm_table_processed, x='axis-1', y='axis-2');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем разделить это пространство главных компонент на сегменты. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5.4\n",
    "Попробуем воспользоваться методом k-means. \n",
    "\n",
    "Подберите оптимальное количество кластеров для метода k-means с помощью коэффициента силуэта, перебирая возможные значения от 2 до 10 включительно. \n",
    "\n",
    "В качестве значения параметра random_state возьмите число 42. Остальные параметры оставьте по умолчанию.\n",
    "\n",
    "1) Судя по полученным результатам, какое количество кластеров лучше всего взять?\n",
    "\n",
    "2) Чему равно максимальное значение коэффициента силуэта? Ответ округлите до двух знаков после точки-разделителя.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5.5\n",
    "Теперь возьмём EM-алгоритм.\n",
    "\n",
    "Подберите оптимальное количество кластеров для EM-алгоритма (GaussianMixture) с помощью коэффициента силуэта, перебирая возможные значения от 2 до 10 включительно.\n",
    "В качестве значения параметра random_state возьмите число 42. Остальные параметры оставьте по умолчанию.\n",
    "\n",
    "\n",
    "1) Судя по полученным результатам, какое количество кластеров лучше всего взять?\n",
    "\n",
    "2) Чему равно максимальное значение коэффициента силуэта? Ответ округлите до двух знаков после точки-разделителя.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5.6\n",
    "Давайте посмотрим на распределение кластеров.\n",
    "\n",
    "1) Сначала нужно определить лучшую модель. Для какой модели с оптимальным количеством кластеров коэффициент силуэта наибольший?\n",
    "* K-Means\n",
    "* GaussianMixture\n",
    "\n",
    "\n",
    "2) Обучите лучшую модель с подобранным ранее количеством кластеров на декомпозированных данных. \n",
    "Сколько клиентов попало в самый большой кластер?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем результаты кластеризации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 5))\n",
    "sns.scatterplot(\n",
    "    data=rfm_table_processed, \n",
    "    x='axis-1', \n",
    "    y='axis-2', \n",
    "    hue=labels,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, у нас есть три сегмента клиентов. Давайте попробуем составить профиль для этих сегментов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5.7\n",
    "\n",
    "Для составления профиля кластеров нам необходимо вернуться от декомпозированных данных к RFM-таблице, очищенной от выбросов.  Сгруппируйте RFM-таблицу по полученным кластерам и рассчитайте среднее по каждому из признаков.\n",
    "\n",
    "Чему равно максимальное среднее значение признака Frequency в полученной таблице? Ответ округлите до целого числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Полярная диаграмма\n",
    "Сейчас мы познакомимся с одним из способов визуализации профиля кластеров — Radar Chart (полярная, или лепестковая, диаграмма). Это графическое представление значений нескольких эквивалентных категорий в форме «паутины».\n",
    "Radar Chart очень часто используется в контексте определения профиля кластеров. На концах «паутины» откладываются оси, которые соответствуют признакам, описывающим объекты. На каждой из осей для каждого кластера откладываются средние значения соответствующих характеристик. Соединив точки по осям, мы получаем многоугольник. \n",
    "Пример полярной диаграммы для задачи кластеризации учеников по интересам:\n",
    "\n",
    "<img src=https://www.datanovia.com/en/wp-content/uploads/2020/12/radar-chart-in-r-customized-fmstb-radar-chart-1.png width=500>\n",
    "\n",
    "На данной диаграмме мы видим визуализацию признаков для одного из кластеров. Видно, что ученики, принадлежащие к данному кластеру, в большей степени увлекаются музыкой (Music), а в меньшей степени — программированием (Programm).\n",
    "\n",
    "В модуле graph_objects библиотеки plotly есть встроенная функция Scatterpolar, которая позволяет построить полярную диаграмму. На основе этой функции мы реализовали собственную функцию plot_cluster_profile(), которая позволяет визуализировать профиль каждого из кластеров в виде полярной диаграммы. У этой функции два параметра: grouped_data — сгруппированные по кластерам характеристики объектов (клиентов), n_clusters — количество кластеров. \n",
    "\n",
    "Главное условие использования полярной диаграммы — все признаки должны быть приведены к единому масштабу с помощью нормализации, где 1 будет означать максимум, а 0 — минимум. Шаг с нормализацией мы также добавили в реализацию функции plot_cluster_profile()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_profile(grouped_data, n_clusters):\n",
    "    # Нормализуем сгруппированные данные, приводя их к масштабу 0-1.\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    grouped_data = pd.DataFrame(scaler.fit_transform(grouped_data), columns=grouped_data.columns)\n",
    "    # Создаем список признаков\n",
    "    features = grouped_data.columns\n",
    "    # Создаем пустую фигуру\n",
    "    fig = go.Figure()\n",
    "    # В цикле визуализируем полярную диаграмму для каждого кластера\n",
    "    for i in range(n_clusters):\n",
    "        # Создаем полярную диаграмму и добавляем ее на общий график\n",
    "        fig.add_trace(go.Scatterpolar(\n",
    "            r=grouped_data.iloc[i].values, # радиусы\n",
    "            theta=features, # название засечек\n",
    "            fill='toself', # заливка многоугольника цветом\n",
    "            name=f'Cluster {i}', # название - номер кластера\n",
    "        ))\n",
    "    # Обновляем параметры фигуры\n",
    "    fig.update_layout(\n",
    "        showlegend=True, # отображение легенды\n",
    "        autosize=False, # устаналиваем свои размеры графика\n",
    "        width=800, # ширина (в пикселях)\n",
    "        height=800, # высота (в пикселях)\n",
    "    )\n",
    "    # Отображаем фигуру\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть удобный инструмент для анализа профиля кластеров. Давайте воспользуемся им.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5.8\n",
    "\n",
    "Визуализируйте профили кластеров в виде полярной диаграммы на основе средних RFM-характеристик, вычисленных для каждого кластера. \n",
    "\n",
    "Проанализируйте кластеры и на основе анализа сопоставьте номер кластера и его описание.\n",
    "\n",
    "Описание кластера:\n",
    "* Кластер соответствует «лояльным» клиентам, которые приносят наибольший доход, совершают покупки чаще всего, а давность их последней покупки наименьшая.\n",
    "* Кластер соответствует «промежуточным» клиентам, которые являются активными, но покупают не так часто и много, как лояльные клиенты. В то же время эти клиенты не являются «потерянными».\n",
    "* Кластер соответствует «потерянным» клиентам, которые купили меньше всего товара, и их последняя покупка была совершена очень давно.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. RFM-сегментация клиентов: часть 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, с помощью RFM-анализа нам удалось выделить три сегмента клиентов. Однако в маркетинге принято оперировать большим их количеством: обычно маркетологи стараются создать стратегию хотя бы для пяти-семи клиентских сегментов в градации от «лояльных» до «потерянных» с промежуточными категориями.\n",
    "\n",
    "Поэтому, получив обратную связь от маркетологов, мы вновь принимаемся за работу, пытаясь модифицировать полученное решение.\n",
    "\n",
    "Ранее мы производили кластеризацию в пространстве главных компонент. Вспомним, что PCA является линейным методом отображения исходного пространства признаков в его сжатую версию.\n",
    "\n",
    "А что если использовать нелинейную трансформацию? Например, алгоритм снижения размерности t-SNE. Давайте попробуем и посмотрим, что получится."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.1\n",
    "Воспользуемся алгоритмом t-SNE и трансформируем RFM-таблицу, очищенную от выбросов, в двухмерное представление. Также заранее позаботимся о масштабировании признаков.\n",
    "\n",
    "Давайте для удобства обернём шаги по предобработке данных в pipeline.\n",
    "\n",
    "Создайте pipeline, который будет содержать следующие шаги:\n",
    "* стандартизация с помощью StandardScaler с параметрами по умолчанию; \n",
    "* алгоритм t-SNE с двумя компонентами, параметрами perplexity=50 и random_state=100.\n",
    "\n",
    "Обучите ваш pipeline на RFM-таблице (очищенной от выбросов), полученной ранее, и примените к ней трансформацию.\n",
    "\n",
    "Чему равно значение дивергенции Кульбака — Лейблера для обученного алгоритма t-SNE? Ответ округлите до двух знаков после точки-разделителя.\n",
    "\n",
    "**Примечание:**\n",
    "Напомним, что дивергенция Кульбака-Лейблера - это функция потерь, которая минимизируется при обучения алгоритма t-SNE. Она показывает меру расстояния между двумя распределениями. \n",
    "\n",
    "Оптимальное значение данной характеристики, найденное в процессе обучения алгоритма t-SNE, хранится в атрибуте kl_divergence_ объекта класса TSNE из библиотеки sklearn. Конечно же, предварительно модель необходимо обучить, чтобы получить это значение.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализировав пространство после декомпозиции с помощью t-SNE, мы получим следующую картину:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 5))\n",
    "sns.scatterplot(data=rfm_table_processed, x='axis-1', y='axis-2');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ожидалось от t-SNE, алгоритм сгруппировал наиболее похожие объекты в подобие кластеров, причём эти кластеры легко определить.\n",
    "\n",
    "Теперь давайте воспользуемся алгоритмами кластеризации, чтобы сформировать новые сегменты клиентов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.2\n",
    "Попробуем воспользоваться методом k-means. \n",
    "Подберите оптимальное количество кластеров для метода k-means с помощью коэффициента силуэта, перебирая возможные значения от 3 до 8 включительно. \n",
    "В качестве значения параметра random_state возьмите число 42. Остальные параметры оставьте по умолчанию.\n",
    "\n",
    "1) Судя по полученным результатам, какое количество кластеров лучше всего взять?\n",
    "\n",
    "2) Чему равно максимальное значение коэффициента силуэта? Ответ округлите до двух знаков после точки-разделителя.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.3\n",
    "Попробуем воспользоваться EM-алгоритом. \n",
    "\n",
    "Подберите оптимальное количество кластеров для EM-алгоритма (GaussianMixture)  с помощью коэффициента силуэта, перебирая возможные значения от 3 до 8 включительно. \n",
    "\n",
    "В качестве значения параметра random_state возьмите число 42. Остальные параметры оставьте по умолчанию.\n",
    "\n",
    "\n",
    "1) Судя по полученным результатам, какое количество кластеров лучше всего взять?\n",
    "\n",
    "2) Чему равно максимальное значение коэффициента силуэта? Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.4\n",
    "Наконец, попробуем воспользоваться алгоритмом алгомеративной кластеризации (AgglomerativeClustering).\n",
    "\n",
    "Подберите оптимальное количество кластеров для алгоритма агломеративной кластеризации с помощью коэффициента силуэта, перебирая возможные значения от 2 до 8 включительно. \n",
    "\n",
    "Все параметры, за исключением числа кластеров, оставьте по умолчанию.\n",
    "\n",
    "\n",
    "1) Судя по полученным результатам, какое количество кластеров лучше всего взять?\n",
    "\n",
    "2) Чему равно максимальное значение коэффициента силуэта? Ответ округлите до двух знаков после точки-разделителя.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Задание 6.5\n",
    "Давайте посмотрим на распределение кластеров.\n",
    "\n",
    "1) Сначала нужно определить лучшую модель. Для какой модели с оптимальным количеством кластеров коэффициент силуэта наибольший?\n",
    "* K-Means\n",
    "* GaussianMixture\n",
    "* AgglomerativeClustering\n",
    "\n",
    "\n",
    "2) Обучите лучшую модель с подобранным ранее количеством кластеров на декомпозированных данных. \n",
    "Сколько клиентов попало в самый большой кластер?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем результаты кластеризации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 5))\n",
    "sns.scatterplot(data=rfm_table_processed, x='axis-1', y='axis-2', hue=model.labels_.astype('str'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Итак, у нас есть 7 сегментов клиентов. Давайте попробуем составить профиль для этих сегментов. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.6\n",
    "\n",
    "Для составления профиля кластеров нам необходимо вернуться от декомпозированных данных к RFM-таблице (очищенной от выбросов).\n",
    "\n",
    "Сгруппируйте RFM-таблицу по полученным кластерам и рассчитайте среднее по каждому из признаков. Для наглядности округлите все значения в столбцах до целого числа.\n",
    "\n",
    "Чему равно максимальное среднее значение признака Recency в полученной таблице? Ответ округлите до целого числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.7\n",
    "Визуализируйте профили кластеров в виде полярной диаграммы на основе средних RFM-характеристик, вычисленных для каждого кластера.\n",
    "\n",
    "Проанализируйте кластеры и на основе анализа сопоставьте номер кластера и его описание.\n",
    "\n",
    "* Кластер соответствует «лояльным» клиентам, которые приносят наибольший доход, совершают покупки чаще всего, а давность их последней покупки наименьшая.\n",
    "* Кластер соответствует «перспективным» клиентам, которые являются активными покупателями, но покупают не так часто и не так много, как лояльные клиенты.\n",
    "* Кластер соответствует «подвисшим» клиентам, которые относительно недавно сделали несколько заказов на небольшие суммы. Потенциально эти клиенты могут быть переведены в кластер «перспективных».\n",
    "* Кластер соответствует клиентам «в зоне риска», которые несколько раз покупали товары на небольшие суммы, однако их последняя покупка была совершена более пяти месяцев назад.\n",
    "* Кластер соответствует клиентам-«новичкам», которые относительно недавно сделали один заказ на небольшую сумму. \n",
    "* Кластер соответствует «спящим» или «почти потерянным» клиентам, которые сделали один заказ на маленькую сумму более семи месяцев назад и больше не возвращались.\n",
    "* Кластер соответствует «потерянным» клиентам, которые купили меньше всего товара, и их последняя покупка была совершена около года назад.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. RFM-кластеризация клиентов: часть 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы построили модель кластеризации для части клиентов.Но как сделать предсказание сегмента для клиентов, которые не попали в обучающую выборку?\n",
    "\n",
    "Вы, вероятно, скажете: «Воспользоваться методом predict()!»\n",
    "\n",
    "Верно, однако всё не так просто.\n",
    "\n",
    "Вспомним, что мы обучали наши алгоритмы кластеризации на сжатом с помощью t-SNE пространстве признаков. То есть, чтобы сделать предсказание для новых объектов, не попавших в выборку, нам необходимо будет совершить трансформацию признаков этих объектов в новое сжатое пространство. \n",
    "\n",
    "Однако проблема t-SNE заключается в том, что алгоритм непараметрический. Это значит, что он, в отличие от таких алгоритмов, как PCA и SVD, не создаёт явной функции отображения. Проще говоря, алгоритм трансформирует пространство признаков для обучающей выборки, но не запоминает, каким образом это делает. Это значит, что, передав в алгоритм новые объекты для сжатия пространства, мы получим абсолютно новое представление пространства, не имеющее отношения к тому, что мы построили для обучающей выборки. То есть произойдёт искажение, что может привести к неверным результатам кластеризации.\n",
    "\n",
    "Именно поэтому у класса TSNE из библиотеки sklearn нет такого метода, как transform(), у него есть только метод fit_transform() — заново обучить алгоритм t-SNE и произвести трансформацию.\n",
    "\n",
    "Как же тогда производить кластеризацию для новых объектов, если мы не можем сжимать размерность для новых данных?\n",
    "\n",
    "Давайте сведём задачу кластеризации к задаче классификации. Действительно, у нас теперь есть истинные метки кластеров, а есть клиенты, которые описываются RFM-характеристиками. Давайте обучим модель, которая на основе RFM-характеристик будет предсказывать клиентский сегмент. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7.1\n",
    "\n",
    "Разделите исходные данные на тренировочную и тестовую выборки в соотношении 80/20. В качестве параметра random_state возьмите число 42.\n",
    "\n",
    "Сколько клиентов попали в тестовую выборку?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше нам осталось только построить несколько моделей и выбрать из них лучшую. \n",
    "Мы знаем, что алгоритм t-SNE является нелинейным методом понижения размерности. Можно смело предположить, что линейные модели, такие как логистическая регрессия, в данной задаче нам мало чем помогут (можете убедиться в этом самостоятельно, обучив модель логистической регрессии на тренировочной выборке и оценив качество на тестовой).\n",
    "\n",
    "Поэтому давайте сразу возьмём тяжелую артиллерию — ансамблевые алгоритмы. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7.2\n",
    "Начнём со случайного леса. С помощью GridSearchCV организуйте перебор параметров случайного леса (RandomForestClassifier) на следующей сетке параметров:\n",
    "\n",
    "```\n",
    "param_grid = {\n",
    "    'max_depth': range(5, 15),\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'n_estimators': [100, 200, 500]\n",
    "}\n",
    "```\n",
    "В качестве параметра random_state для модели случайного леса используйте число 42.\n",
    "В качестве метрики используйте accuracy. Количество фолдов для кросс-валидации — 5.\n",
    "\n",
    "1) Обучите GridSearchCV на тренировочной выборке. Чему равна оптимальная максимальная глубина деревьев в случайном лесу?\n",
    "\n",
    "2) С помощью лучшей модели сделайте предсказание для тестовой выборки и рассчитайте метрику accuracy. Ответ округлите до трёх знаков после точки-разделителя.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, значение метрики accuracy очень высокое, но не идеальное. Давайте попробуем его улучшить, воспользовавшись бустингом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7.3\n",
    "С помощью GridSearchCV организуйте перебор параметров градиентного бустинга (GradientBoostingClassifier) на следующей сетке параметров:\n",
    "```\n",
    "param_grid = {\n",
    "    'max_depth': range(3, 7),\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'n_estimators': [100, 200, 500]\n",
    "}\n",
    "```\n",
    "\n",
    "В качестве параметра random_state для модели градиентного бустинга используйте число 42.\n",
    "В качестве метрики используйте accuracy. Количество фолдов для кросс-валидации — 5. \n",
    "\n",
    "1) Обучите GridSearchCV на тренировочной выборке. Чему равна оптимальная максимальная глубина деревьев в градиентном бустинге?\n",
    "Ответ: 6\n",
    "2) С помощью лучшей модели сделайте предсказание для тестовой выборки и рассчитайте метрику accuracy. Ответ округлите до трёх знаков после точки-разделителя.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, мы справились с проблемой непараметричности t-SNE и смогли перейти от решения задачи кластеризации к задаче классификации. Теперь у нас есть модель, которая на основе RFM-характерик клиента автоматически определяет его сегмент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
